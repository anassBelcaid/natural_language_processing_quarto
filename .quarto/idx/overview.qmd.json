{"title":"Introduction to Natural Language Processing Course","markdown":{"yaml":{"title":"Introduction to Natural Language Processing Course","author":"A.Belcaid","date":"09-01-2025","format":{"html":{"toc":true,"toc-depth":3,"number-sections":true,"code-fold":true,"fig-cap-location":"bottom"}},"echo":true,"warning":false,"bibliography":"references.bib"},"headingText":"Course Overview","headingAttr":{"id":"sec-overview","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n:::{.callout-note}\n## Course Structure\n- **Duration**: 14 weeks total\n- **Format**: Student-led research presentations + practical sessions\n- **Target**: Fifth-year computer science students\n- **Prerequisites**: Machine Learning, Python programming, Linear Algebra\n:::\n\n```{mermaid}\n%%| fig-cap: \"Course Timeline and Structure\"\n%%| label: fig-timeline\ngantt\n    title Course Timeline\n    dateFormat  YYYY-MM-DD\n    section Topic Presentations\n    Week 1 - NLP Fundamentals     :active, w1, 2024-09-01, 7d\n    Week 2 - Language Models      :w2, after w1, 7d\n    Week 3 - Word Embeddings      :w3, after w2, 7d\n    Week 4 - Neural Networks      :w4, after w3, 7d\n    Week 5 - Transformers         :w5, after w4, 7d\n    Week 6 - Large LMs            :w6, after w5, 7d\n    Week 7 - Ethics & Evaluation  :w7, after w6, 7d\n    section Project Phase\n    Project Development           :p1, after w7, 21d\n    Final Presentations          :p2, after p1, 21d\n```\n\n**First 7 weeks**: Student presentations (2 hours) + Hands-on practice (1 hour)  \n**Last 7 weeks**: Project presentations and peer evaluation\n\n# Part I: Weekly Topics for Student Presentations {#sec-topics}\n\n## Week 1: Fundamentals of Natural Language Processing {#sec-week1}\n\n![NLP Pipeline Overview](https://media.geeksforgeeks.org/wp-content/uploads/20230118132334/NLP-Pipeline-GIF.gif){#fig-nlp-pipeline fig-alt=\"A flowchart showing the typical NLP processing pipeline from raw text to applications\"}\n\n### Topic Overview\n\n- **History and Evolution**: From rule-based systems to modern neural approaches\n- **Core Challenges**: Ambiguity, context, pragmatics, and world knowledge\n- **Text Preprocessing**: Tokenization, normalization, and cleaning techniques\n- **Linguistic Foundations**: Morphology, syntax, semantics, and pragmatics\n\n:::{.callout-important}\n## Key Resources\n- [NLTK Book](https://www.nltk.org/book/) - Comprehensive introduction\n- [spaCy Documentation](https://spacy.io/) - Industrial-strength NLP\n- [Stanford NLP Group](https://nlp.stanford.edu/) - Research papers and resources\n:::\n\n### Learning Objectives\n\n1. Understand the **scope and applications** of NLP across industries\n2. Master the **text preprocessing pipeline** using industry-standard tools\n3. Identify and analyze **linguistic ambiguities** and computational challenges\n4. Implement **tokenization algorithms** for different languages and domains\n\n### Hands-on Session\n\n```python\n# Sample preprocessing pipeline\nimport nltk\nimport spacy\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\n\n# Text preprocessing demonstration\ntext = \"The researchers are researching research papers.\"\n# Expected output: tokens, stems, lemmas, POS tags\n```\n\n**Activities**:\n- Building a custom tokenizer for social media text\n- Comparing stemming vs. lemmatization performance\n- Multilingual preprocessing challenges\n\n## Week 2: Statistical Language Models and N-grams {#sec-week2}\n\n### Topic Overview\n\nStatistical language modeling forms the foundation of modern NLP. This week covers:\n\n- **Probability Theory** in language: Chain rule, independence assumptions\n- **N-gram Models**: Mathematical formulation and implementation details  \n- **Smoothing Techniques**: Handling zero probabilities and data sparsity\n- **Evaluation Metrics**: Perplexity, cross-entropy, and information theory\n\n```{mermaid}\n%%| fig-cap: \"N-gram Model Hierarchy\"\n%%| label: fig-ngrams\ngraph TD\n    # A[Unigram Model<br/>P(w)] --> B[Bigram Model<br/>P(w|w-1)]\n    # B --> C[Trigram Model<br/>P(w|w-2,w-1)]\n    # C --> D[N-gram Model<br/>P(w|w-n+1...w-1)]\n\n    A --> E[Independence<br/>High bias, Low variance]\n    D --> F[Context Dependence<br/>Low bias, High variance]\n```\n\n:::{.callout-tip}\n## Mathematical Foundation\nThe n-gram probability is calculated as:\n$$P(w_i|w_{i-n+1}^{i-1}) = \\frac{C(w_{i-n+1}^{i})}{C(w_{i-n+1}^{i-1})}$$\n\nWhere $C(·)$ represents the count function in the training corpus.\n:::\n\n### Learning Objectives\n\n- Build and evaluate n-gram language models from scratch\n- Understand the **bias-variance tradeoff** in model complexity\n- Apply various smoothing techniques (Laplace, Good-Turing, Kneser-Ney)\n- Calculate and interpret perplexity scores\n\n### Hands-on Session\n\n**Implementation Tasks**:\n- N-gram model training on different corpus sizes\n- Perplexity calculation and analysis\n- Smoothing method comparison study\n- Text generation using trained models\n\n## Week 3: Word Representations and Embeddings {#sec-week3}\n\n![Word Embedding Space](https://via.placeholder.com/500x400/2196F3/FFFFFF?text=Word+Vectors+in+Semantic+Space:+King+−+Man+%2B+Woman+≈+Queen){#fig-embeddings fig-alt=\"Visualization of word embeddings showing semantic relationships in vector space\"}\n\n### Topic Overview\n\nThe transition from sparse to dense word representations revolutionized NLP:\n\n- **Distributional Semantics**: \"You shall know a word by the company it keeps\"\n- **Word2Vec Algorithms**: Skip-gram and Continuous Bag of Words (CBOW)\n- **Global Vectors (GloVe)**: Matrix factorization approach to embeddings\n- **FastText**: Subword information and out-of-vocabulary handling\n\n:::{.callout-note}\n## Word2Vec Intuition\n- **Skip-gram**: Predicts context words given target word\n- **CBOW**: Predicts target word given context words\n- Both use hierarchical softmax or negative sampling for efficiency\n:::\n\n### Key Resources\n\n- [Word2Vec Paper](https://arxiv.org/abs/1301.3781) - Original Mikolov et al. work\n- [GloVe: Global Vectors](https://nlp.stanford.edu/projects/glove/) - Stanford implementation\n- [FastText](https://fasttext.cc/) - Facebook's subword embeddings\n\n### Learning Objectives\n\n1. Understand limitations of **one-hot encoding** and sparse representations\n2. Master the mathematics behind **Word2Vec training objectives**\n3. Implement **embedding evaluation** using intrinsic and extrinsic methods\n4. Analyze **semantic and syntactic** relationships in embedding spaces\n\n### Hands-on Session\n\n```python\n# Word2Vec training example\nfrom gensim.models import Word2Vec\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\n\n# Training and visualization pipeline\nmodel = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n# Visualize embeddings with t-SNE\n```\n\n**Practical Exercises**:\n- Training Word2Vec on domain-specific corpora\n- t-SNE visualization of embedding clusters\n- Word analogy tasks: \"king - man + woman = ?\"\n- Cross-lingual embedding alignment\n\n## Week 4: Neural Networks for NLP {#sec-week4}\n\n### Topic Overview\n\nThe neural revolution in NLP began with architectures designed for sequential data:\n\n- **Recurrent Neural Networks (RNNs)**: Processing variable-length sequences\n- **Long Short-Term Memory (LSTM)**: Solving the vanishing gradient problem\n- **Gated Recurrent Units (GRUs)**: Simplified gating mechanisms\n- **Bidirectional Networks**: Capturing both forward and backward context\n\n```{mermaid}\n%%| fig-cap: \"RNN Architecture Evolution\"\n%%| label: fig-rnn-evolution\ngraph LR\n    A[Vanilla RNN<br/>Vanishing Gradients] --> B[LSTM<br/>Forget Gate + Input Gate + Output Gate]\n    B --> C[GRU<br/>Reset Gate + Update Gate]\n    C --> D[BiLSTM<br/>Forward + Backward Processing]\n    \n    B --> E[Applications:<br/>Language Modeling<br/>Sequence Classification<br/>Named Entity Recognition]\n```\n\n### Learning Objectives\n\n- Design neural architectures for **sequence processing** tasks\n- Understand **gradient flow** in recurrent connections\n- Implement **bidirectional processing** for improved context modeling\n- Apply **regularization techniques** specific to sequential data\n\n### Hands-on Session\n\n**Implementation Focus**:\n- RNN-based language model implementation\n- LSTM vs. GRU comparison on sequence classification\n- Gradient clipping and other training stabilization techniques\n- Attention visualization in sequence-to-sequence models\n\n## Week 5: Attention Mechanisms and Transformers {#sec-week5}\n\n![Transformer Architecture](https://via.placeholder.com/600x450/FF9800/FFFFFF?text=Transformer+Architecture:+Self-Attention+%2B+Feed-Forward+%2B+Residual+Connections){#fig-transformer fig-alt=\"Detailed diagram of the Transformer architecture showing encoder-decoder structure\"}\n\n### Topic Overview\n\nThe attention mechanism fundamentally changed how we process sequences:\n\n- **Attention Intuition**: Differentiable dictionary lookup mechanism\n- **Self-Attention**: Query, Key, Value matrices and scaled dot-product\n- **Multi-Head Attention**: Parallel attention computations with different representations\n- **Transformer Architecture**: Complete replacement of recurrence with attention\n\n:::{.callout-important}\n## Attention Formula\nThe scaled dot-product attention is computed as:\n$$\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n\nWhere $Q$, $K$, $V$ are query, key, and value matrices respectively.\n:::\n\n### Key Resources\n\n- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Original Transformer paper\n- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) - Visual explanation\n- [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor) - Reference implementation\n\n### Learning Objectives\n\n1. Grasp the **mathematical intuition** behind attention mechanisms\n2. Understand **positional encoding** and why it's necessary\n3. Implement **multi-head attention** from scratch\n4. Analyze **computational complexity** advantages over RNNs\n\n### Hands-on Session\n\n```python\n# Self-attention implementation\nimport torch\nimport torch.nn as nn\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.d_model = d_model\n        self.num_heads = num_heads\n        # Implementation details...\n```\n\n**Practical Tasks**:\n- Implementing scaled dot-product attention\n- Building a mini-Transformer for sequence classification\n- Attention weight visualization and interpretation\n- Positional encoding analysis\n\n## Week 6: Large Language Models and Pre-training {#sec-week6}\n\n### Topic Overview\n\nThe era of large-scale pre-trained models has transformed NLP applications:\n\n- **Pre-training Paradigms**: From word prediction to masked language modeling\n- **BERT Family**: Bidirectional encoder representations from transformers\n- **GPT Series**: Autoregressive language model scaling\n- **Transfer Learning**: Fine-tuning strategies for downstream tasks\n\n```{mermaid}\n%%| fig-cap: \"Evolution of Large Language Models\"\n%%| label: fig-llm-timeline\ntimeline\n    title LLM Evolution Timeline\n    2018 : BERT (Google)\n         : GPT-1 (OpenAI)\n         : ELMo (AllenNLP)\n    2019 : GPT-2\n         : RoBERTa\n         : XLNet\n    2020 : GPT-3\n         : T5\n         : ELECTRA\n    2021 : PaLM\n         : Codex\n         : WebGPT\n    2022 : ChatGPT\n         : InstructGPT\n         : LaMDA\n    2023 : GPT-4\n         : Claude\n         : LLaMA\n```\n\n:::{.callout-note}\n## Pre-training Objectives\n- **Masked Language Modeling (MLM)**: Predict masked tokens (BERT)\n- **Causal Language Modeling (CLM)**: Predict next token (GPT)\n- **Prefix Language Modeling**: Hybrid approach (GLM, PaLM)\n:::\n\n### Learning Objectives\n\n- Understand different **pre-training strategies** and their trade-offs\n- Master **transfer learning** concepts for NLP applications\n- Analyze **scaling laws** and emergent capabilities in large models\n- Implement **fine-tuning pipelines** for specific tasks\n\n### Hands-on Session\n\n**Practical Applications**:\n- Fine-tuning BERT for text classification using [Hugging Face](https://huggingface.co/)\n- Prompt engineering with GPT models\n- Model comparison across different architectures\n- Efficient fine-tuning with parameter-efficient methods (LoRA, adapters)\n\n## Week 7: Evaluation and Ethics in NLP {#sec-week7}\n\n### Topic Overview\n\nResponsible AI development requires comprehensive evaluation and ethical considerations:\n\n- **Evaluation Methodologies**: Intrinsic vs. extrinsic evaluation frameworks\n- **Bias Detection**: Identifying and measuring algorithmic bias\n- **Fairness Metrics**: Demographic parity, equalized odds, individual fairness\n- **Environmental Impact**: Carbon footprint of large model training\n\n![Bias in NLP Systems](https://via.placeholder.com/550x350/F44336/FFFFFF?text=Bias+Sources:+Data+%2B+Algorithms+%2B+Applications+%3D+Societal+Impact){#fig-bias fig-alt=\"Diagram showing how bias enters NLP systems through data, algorithms, and applications\"}\n\n:::{.callout-warning}\n## Ethical Considerations\n- **Representation Bias**: Training data may not represent all populations\n- **Measurement Bias**: Evaluation metrics may favor certain groups\n- **Evaluation Bias**: Test sets may contain demographic skews\n- **Deployment Bias**: Real-world usage may differ from intended applications\n:::\n\n### Key Resources\n\n- [AI Fairness 360](https://aif360.readthedocs.io/) - IBM's bias detection toolkit\n- [What We Can't Measure, We Can't Understand](https://arxiv.org/abs/2109.09315) - Measurement in ML\n- [Blodgett et al., 2020](https://arxiv.org/abs/2005.14050) - Language models and bias\n\n### Learning Objectives\n\n1. Design **comprehensive evaluation frameworks** for NLP systems\n2. Identify and **quantify algorithmic bias** using statistical methods\n3. Implement **bias mitigation techniques** at different pipeline stages\n4. Consider **broader societal implications** of NLP deployment\n\n### Hands-on Session\n\n```python\n# Bias evaluation example\nfrom sklearn.metrics import confusion_matrix\nimport pandas as pd\n\n# Fairness metric calculation\ndef demographic_parity_difference(y_true, y_pred, sensitive_attr):\n    # Implementation for measuring bias across groups\n    pass\n```\n\n**Evaluation Tasks**:\n- Word embedding bias testing (WEAT, SEAT)\n- Fairness evaluation across demographic groups\n- Carbon footprint estimation for model training\n- Adversarial testing for robustness\n\n# Part II: Student Project Presentations {#sec-projects}\n\n## Project Categories and Detailed Descriptions\n\n### Category A: Text Classification and Analysis {#sec-classification}\n\n#### Project 1: Multi-label News Article Classification {#sec-project1}\n\n**Objective**: Build a robust multi-label classification system for news articles\n\n- **Dataset**: [Reuters-21578](http://www.daviddlewis.com/resources/testcollections/reuters21578/) or [BBC News Dataset](https://www.kaggle.com/c/learn-ai-bbc)\n- **Techniques**: Compare traditional ML (TF-IDF + SVM) vs. modern approaches (BERT, RoBERTa)\n- **Evaluation**: Multi-label F1, Hamming loss, subset accuracy\n- **Extensions**: Hierarchical classification, active learning for label efficiency\n\n:::{.callout-tip}\n## Technical Challenges\n- **Label Imbalance**: Some categories have very few examples\n- **Label Correlation**: Economic news often overlaps with political news\n- **Temporal Drift**: News topics evolve over time\n:::\n\n#### Project 2: Aspect-Based Sentiment Analysis {#sec-project2}\n\n**Objective**: Joint extraction of aspects and sentiment classification\n\n- **Dataset**: [SemEval ABSA datasets](http://alt.qcri.org/semeval2016/task5/), restaurant/hotel reviews\n- **Techniques**: Joint models for aspect extraction and sentiment classification\n- **Evaluation**: Aspect-level F1 scores, sentiment accuracy per aspect\n- **Extensions**: Cross-domain adaptation, multilingual ABSA\n\n```python\n# Example aspect-sentiment pairs\ntext = \"The pizza was delicious but the service was terrible.\"\naspects = [\n    (\"pizza\", \"positive\"),\n    (\"service\", \"negative\")\n]\n```\n\n#### Project 3: Fake News Detection with Explainability {#sec-project3}\n\n**Objective**: Build interpretable fake news detection systems\n\n- **Dataset**: [FakeNewsNet](https://github.com/KaiDMML/FakeNewsNet), [LIAR dataset](https://www.cs.ucsb.edu/~william/data/liar_dataset.zip)\n- **Techniques**: Feature engineering + deep learning + attention visualization\n- **Evaluation**: Classification metrics + human evaluation of explanations\n- **Extensions**: Multi-modal fake news detection (text + images)\n\n### Category B: Information Extraction and Retrieval {#sec-extraction}\n\n#### Project 4: Named Entity Recognition for Specialized Domains {#sec-project4}\n\n**Objective**: Develop domain-specific NER systems\n\n- **Dataset**: [BioBERT datasets](https://github.com/dmis-lab/biobert) (biomedical) or financial NER\n- **Techniques**: CRF vs. BERT-based sequence labeling\n- **Evaluation**: Entity-level F1, error analysis by entity type\n- **Extensions**: Few-shot NER, nested entity recognition\n\n#### Project 5: Open-Domain Question Answering System {#sec-project5}\n\n**Objective**: Build end-to-end question answering pipeline\n\n- **Dataset**: [Natural Questions](https://ai.google.com/research/NaturalQuestions/), [MS MARCO](https://microsoft.github.io/msmarco/)\n- **Architecture**: Dense Passage Retrieval + Reading Comprehension\n- **Evaluation**: Exact match, F1, answer coverage analysis\n- **Extensions**: Multi-hop reasoning, conversational QA\n\n```{mermaid}\n%%| fig-cap: \"Question Answering System Architecture\"\n%%| label: fig-qa-system\ngraph TB\n    A[Question] --> B[Query Encoder]\n    B --> C[Passage Retrieval]\n    C --> D[Passage Encoder]\n    D --> E[Answer Extraction]\n    E --> F[Answer]\n    \n    G[(Knowledge Base<br/>Wikipedia/Web)] --> C\n    H[Retriever Model<br/>DPR/ColBERT] --> C\n    I[Reader Model<br/>BERT/T5] --> E\n```\n\n#### Project 6: Automatic Fact Verification {#sec-project6}\n\n**Objective**: Verify claims against evidence sources\n\n- **Dataset**: [FEVER](https://fever.ai/dataset/fever.html) (Fact Extraction and VERification)\n- **Pipeline**: Evidence retrieval → Textual entailment → Verdict prediction\n- **Evaluation**: FEVER score, evidence selection accuracy\n- **Extensions**: Real-time fact-checking, claim generation\n\n### Category C: Text Generation and Summarization {#sec-generation}\n\n#### Project 7: Neural Abstractive Text Summarization {#sec-project7}\n\n**Objective**: Generate coherent abstractive summaries\n\n- **Dataset**: [CNN/DailyMail](https://github.com/abisee/cnn-dailymail), [XSum](https://github.com/EdinburghNLP/XSum)\n- **Techniques**: Encoder-decoder with attention, copy mechanisms, coverage\n- **Evaluation**: ROUGE scores, BERTScore, factual consistency\n- **Extensions**: Multi-document summarization, controllable length\n\n#### Project 8: Dialogue System with Personality {#sec-project8}\n\n**Objective**: Develop persona-consistent chatbots\n\n- **Dataset**: [PersonaChat](https://github.com/facebookresearch/ParlAI/tree/main/projects/personachat), [Blended Skill Talk](https://github.com/facebookresearch/ParlAI/tree/main/projects/blended_skill_talk)\n- **Techniques**: Persona-aware generation, retrieval-augmented responses\n- **Evaluation**: Automatic metrics + human evaluation for consistency\n- **Extensions**: Emotional intelligence, long-term memory\n\n#### Project 9: Creative Writing Assistant {#sec-project9}\n\n**Objective**: AI-powered creative content generation\n\n- **Dataset**: [WritingPrompts](https://www.reddit.com/r/WritingPrompts/), poetry corpora\n- **Techniques**: Fine-tuned GPT models with controlled generation\n- **Evaluation**: Creativity metrics, human preference studies, style analysis\n- **Extensions**: Interactive story writing, genre transfer\n\n### Category D: Multilingual and Low-Resource NLP {#sec-multilingual}\n\n#### Project 10: Cross-lingual Text Classification {#sec-project10}\n\n**Objective**: Zero-shot transfer across languages\n\n- **Dataset**: [MLDoc](https://github.com/facebookresearch/MLDoc), [XNLI](https://github.com/facebookresearch/XNLI)\n- **Techniques**: Multilingual BERT, cross-lingual word embeddings\n- **Evaluation**: Zero-shot transfer performance analysis\n- **Extensions**: Few-shot adaptation, code-switching handling\n\n#### Project 11: Machine Translation for Low-Resource Languages {#sec-project11}\n\n**Objective**: Improve translation for under-resourced languages\n\n- **Dataset**: [OPUS collections](http://opus.nlpl.eu/), WMT shared tasks\n- **Techniques**: Transfer learning, back-translation, multilingual models\n- **Evaluation**: BLEU, chrF, human evaluation, error analysis\n- **Extensions**: Pivot translation, unsupervised MT\n\n### Category E: Specialized Applications {#sec-specialized}\n\n#### Project 12: Legal Document Analysis {#sec-project12}\n\n**Objective**: Automated legal document processing\n\n- **Dataset**: Legal case documents, contracts, legislative texts\n- **Techniques**: Domain-adapted BERT, hierarchical document modeling\n- **Evaluation**: Legal expert evaluation, domain-specific metrics\n- **Extensions**: Legal precedent search, contract risk assessment\n\n#### Project 13: Medical Text Mining {#sec-project13}\n\n**Objective**: Clinical decision support through NLP\n\n- **Dataset**: [MIMIC-III](https://mimic.mit.edu/) clinical notes, PubMed abstracts\n- **Techniques**: BioBERT, clinical NER, relation extraction\n- **Evaluation**: Medical accuracy, clinical utility assessment\n- **Extensions**: Drug interaction prediction, diagnosis assistance\n\n#### Project 14: Mental Health Detection in Social Media {#sec-project14}\n\n**Objective**: Early detection of mental health indicators\n\n- **Dataset**: Reddit mental health datasets, Twitter emotion data\n- **Techniques**: Multi-modal analysis, temporal pattern modeling\n- **Evaluation**: Precision/recall for sensitive detection, ethical review\n- **Extensions**: Crisis intervention systems, privacy-preserving methods\n\n:::{.callout-warning}\n## Ethical Considerations for Mental Health Projects\n- **Privacy**: Anonymization and consent requirements\n- **Harm Prevention**: Avoiding false positives in crisis detection\n- **Professional Oversight**: Collaboration with mental health professionals\n- **Bias Mitigation**: Ensuring fair representation across demographics\n:::\n\n# Assessment Criteria {#sec-assessment}\n\n## Topic Presentations (Weeks 1-7) {#sec-topic-assessment}\n\n| Criterion | Weight | Description |\n|-----------|--------|-------------|\n| **Content Quality** | 40% | Research depth, technical accuracy, concept coverage |\n| **Presentation Skills** | 30% | Communication clarity, visual aids, audience engagement |\n| **Technical Implementation** | 30% | Code quality, demonstration effectiveness, innovation |\n\n: Assessment rubric for weekly topic presentations {#tbl-topic-rubric}\n\n## Project Presentations (Weeks 8-14) {#sec-project-assessment}\n\n| Criterion | Weight | Key Evaluation Points |\n|-----------|--------|---------------------|\n| **Technical Rigor** | 35% | Methodology selection, implementation quality, experimental design |\n| **Innovation** | 25% | Novel approaches, creative problem-solving, original insights |\n| **Results & Analysis** | 25% | Comprehensive evaluation, error analysis, baseline comparison |\n| **Communication** | 15% | Clear presentation, professional documentation, visualizations |\n\n: Assessment rubric for final project presentations {#tbl-project-rubric}\n\n:::{.callout-note}\n## Peer Evaluation Component\nStudents will also evaluate their peers' presentations using a structured rubric, contributing 10% to the final grade. This encourages active engagement and critical thinking.\n:::\n\n# Resources and Tools {#sec-resources}\n\n## Essential Python Libraries\n\n```python\n# Core NLP libraries\nimport nltk              # Natural Language Toolkit\nimport spacy             # Industrial-strength NLP\nimport transformers      # Hugging Face Transformers\nimport torch            # PyTorch for deep learning\nimport tensorflow as tf # TensorFlow alternative\n\n# Specialized libraries\nimport gensim           # Topic modeling and word embeddings\nimport scikit-learn     # Traditional ML algorithms\nimport datasets         # Hugging Face datasets\nimport evaluate         # Evaluation metrics\n```\n\n## Dataset Repositories\n\n- **[Hugging Face Datasets](https://huggingface.co/datasets)**: 10,000+ datasets for NLP\n- **[Papers with Code](https://paperswithcode.com/datasets)**: Benchmark datasets with leaderboards\n- **[Google Dataset Search](https://datasetsearch.research.google.com/)**: Comprehensive dataset discovery\n- **[Academic Torrents](https://academictorrents.com/)**: Large-scale research datasets\n\n## Evaluation Tools and Metrics\n\n- **Text Generation**: BLEU, ROUGE, BERTScore, METEOR\n- **Classification**: Precision, Recall, F1, AUC-ROC\n- **Sequence Labeling**: seqeval, entity-level F1\n- **Bias and Fairness**: Fairlearn, AI Fairness 360\n\n# Timeline and Milestones {#sec-timeline}\n\n```{mermaid}\n%%| fig-cap: \"Detailed Course Timeline with Milestones\"\n%%| label: fig-detailed-timeline\ngantt\n    title Detailed Course Timeline\n    dateFormat  YYYY-MM-DD\n    section Topic Presentations\n    Week 1: NLP Fundamentals      :active, t1, 2024-09-01, 7d\n    Week 2: Language Models       :t2, after t1, 7d\n    Week 3: Word Embeddings       :t3, after t2, 7d\n    Week 4: Neural Networks       :t4, after t3, 7d\n    Week 5: Transformers          :t5, after t4, 7d\n    Week 6: Large Language Models :t6, after t5, 7d\n    Week 7: Ethics & Evaluation   :t7, after t6, 7d\n    section Milestones\n    Project Proposal Due          :milestone, m1, 2024-10-01, 0d\n    Progress Check Meeting        :milestone, m2, 2024-11-01, 0d\n    Final Presentation           :milestone, m3, 2024-12-01, 0d\n    section Project Development\n    Project Phase 1              :p1, after t7, 21d\n    Project Phase 2              :p2, after p1, 21d\n    Final Presentations          :p3, after p2, 14d\n```\n\n## Key Milestones\n\n:::{.panel-tabset}\n\n### Week 4: Mid-Course Checkpoint\n- **Project proposal submission** (2-page document)\n- **Literature review** progress check\n- **Dataset acquisition** and preliminary analysis\n- **Technical approach** validation with instructor\n\n### Week 7: Proposal Presentations\n- **5-minute project pitches** to class\n- **Peer feedback** and suggestions\n- **Final project scope** confirmation\n- **Team formation** (if applicable)\n\n### Week 10: Progress Review\n- **Interim results** presentation\n- **Technical challenges** discussion\n- **Methodology adjustments** if needed\n- **Timeline reassessment** and planning\n\n### Week 13-14: Final Presentations\n- **15-minute presentations** with Q&A\n- **Live demonstrations** of working systems\n- **Peer evaluation** and feedback\n- **Industry guest evaluators** (when possible)\n\n:::\n\n# Additional Course Information {#sec-additional}\n\n## Collaboration and Academic Integrity\n\n- **Individual Work**: Weekly topic presentations must be completed individually\n- **Team Projects**: Final projects may be completed in teams of maximum 2 students\n- **Code Sharing**: All implementations must be original with proper attribution\n- **Plagiarism Policy**: Zero tolerance for academic dishonesty\n\n## Technical Requirements\n\n:::{.callout-important}\n## Submission Requirements\n- **Version Control**: All projects must use Git with clear commit history\n- **Reproducibility**: Include requirements.txt and detailed setup instructions\n- **Documentation**: README with project description, usage, and results\n- **Public Repository**: GitHub repository with appropriate license\n:::\n\n## Support and Office Hours\n\n- **Weekly Office Hours**: Tuesdays 2-4 PM and Thursdays 10-12 PM\n- **Online Forum**: Course Slack workspace for peer discussion\n- **Technical Support**: TA sessions for implementation help\n- **Guest Speakers**: Industry professionals and researchers (select weeks)\n\n## Computing Resources\n\nStudents have access to:\n- **Local GPUs**: NVIDIA RTX 4090 for model training\n- **Cloud Credits**: $100 Google Cloud Platform credits per student\n- **Cluster Access**: University HPC cluster for large-scale experiments\n- **Pretrained Models**: Access to Hugging Face Pro for latest models\n\n---\n\n*This course syllabus is subject to updates based on student needs and emerging trends in NLP research. All changes will be communicated through the course management system.*\n","srcMarkdownNoYaml":"\n\n# Course Overview {#sec-overview}\n\n:::{.callout-note}\n## Course Structure\n- **Duration**: 14 weeks total\n- **Format**: Student-led research presentations + practical sessions\n- **Target**: Fifth-year computer science students\n- **Prerequisites**: Machine Learning, Python programming, Linear Algebra\n:::\n\n```{mermaid}\n%%| fig-cap: \"Course Timeline and Structure\"\n%%| label: fig-timeline\ngantt\n    title Course Timeline\n    dateFormat  YYYY-MM-DD\n    section Topic Presentations\n    Week 1 - NLP Fundamentals     :active, w1, 2024-09-01, 7d\n    Week 2 - Language Models      :w2, after w1, 7d\n    Week 3 - Word Embeddings      :w3, after w2, 7d\n    Week 4 - Neural Networks      :w4, after w3, 7d\n    Week 5 - Transformers         :w5, after w4, 7d\n    Week 6 - Large LMs            :w6, after w5, 7d\n    Week 7 - Ethics & Evaluation  :w7, after w6, 7d\n    section Project Phase\n    Project Development           :p1, after w7, 21d\n    Final Presentations          :p2, after p1, 21d\n```\n\n**First 7 weeks**: Student presentations (2 hours) + Hands-on practice (1 hour)  \n**Last 7 weeks**: Project presentations and peer evaluation\n\n# Part I: Weekly Topics for Student Presentations {#sec-topics}\n\n## Week 1: Fundamentals of Natural Language Processing {#sec-week1}\n\n![NLP Pipeline Overview](https://media.geeksforgeeks.org/wp-content/uploads/20230118132334/NLP-Pipeline-GIF.gif){#fig-nlp-pipeline fig-alt=\"A flowchart showing the typical NLP processing pipeline from raw text to applications\"}\n\n### Topic Overview\n\n- **History and Evolution**: From rule-based systems to modern neural approaches\n- **Core Challenges**: Ambiguity, context, pragmatics, and world knowledge\n- **Text Preprocessing**: Tokenization, normalization, and cleaning techniques\n- **Linguistic Foundations**: Morphology, syntax, semantics, and pragmatics\n\n:::{.callout-important}\n## Key Resources\n- [NLTK Book](https://www.nltk.org/book/) - Comprehensive introduction\n- [spaCy Documentation](https://spacy.io/) - Industrial-strength NLP\n- [Stanford NLP Group](https://nlp.stanford.edu/) - Research papers and resources\n:::\n\n### Learning Objectives\n\n1. Understand the **scope and applications** of NLP across industries\n2. Master the **text preprocessing pipeline** using industry-standard tools\n3. Identify and analyze **linguistic ambiguities** and computational challenges\n4. Implement **tokenization algorithms** for different languages and domains\n\n### Hands-on Session\n\n```python\n# Sample preprocessing pipeline\nimport nltk\nimport spacy\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\n\n# Text preprocessing demonstration\ntext = \"The researchers are researching research papers.\"\n# Expected output: tokens, stems, lemmas, POS tags\n```\n\n**Activities**:\n- Building a custom tokenizer for social media text\n- Comparing stemming vs. lemmatization performance\n- Multilingual preprocessing challenges\n\n## Week 2: Statistical Language Models and N-grams {#sec-week2}\n\n### Topic Overview\n\nStatistical language modeling forms the foundation of modern NLP. This week covers:\n\n- **Probability Theory** in language: Chain rule, independence assumptions\n- **N-gram Models**: Mathematical formulation and implementation details  \n- **Smoothing Techniques**: Handling zero probabilities and data sparsity\n- **Evaluation Metrics**: Perplexity, cross-entropy, and information theory\n\n```{mermaid}\n%%| fig-cap: \"N-gram Model Hierarchy\"\n%%| label: fig-ngrams\ngraph TD\n    # A[Unigram Model<br/>P(w)] --> B[Bigram Model<br/>P(w|w-1)]\n    # B --> C[Trigram Model<br/>P(w|w-2,w-1)]\n    # C --> D[N-gram Model<br/>P(w|w-n+1...w-1)]\n\n    A --> E[Independence<br/>High bias, Low variance]\n    D --> F[Context Dependence<br/>Low bias, High variance]\n```\n\n:::{.callout-tip}\n## Mathematical Foundation\nThe n-gram probability is calculated as:\n$$P(w_i|w_{i-n+1}^{i-1}) = \\frac{C(w_{i-n+1}^{i})}{C(w_{i-n+1}^{i-1})}$$\n\nWhere $C(·)$ represents the count function in the training corpus.\n:::\n\n### Learning Objectives\n\n- Build and evaluate n-gram language models from scratch\n- Understand the **bias-variance tradeoff** in model complexity\n- Apply various smoothing techniques (Laplace, Good-Turing, Kneser-Ney)\n- Calculate and interpret perplexity scores\n\n### Hands-on Session\n\n**Implementation Tasks**:\n- N-gram model training on different corpus sizes\n- Perplexity calculation and analysis\n- Smoothing method comparison study\n- Text generation using trained models\n\n## Week 3: Word Representations and Embeddings {#sec-week3}\n\n![Word Embedding Space](https://via.placeholder.com/500x400/2196F3/FFFFFF?text=Word+Vectors+in+Semantic+Space:+King+−+Man+%2B+Woman+≈+Queen){#fig-embeddings fig-alt=\"Visualization of word embeddings showing semantic relationships in vector space\"}\n\n### Topic Overview\n\nThe transition from sparse to dense word representations revolutionized NLP:\n\n- **Distributional Semantics**: \"You shall know a word by the company it keeps\"\n- **Word2Vec Algorithms**: Skip-gram and Continuous Bag of Words (CBOW)\n- **Global Vectors (GloVe)**: Matrix factorization approach to embeddings\n- **FastText**: Subword information and out-of-vocabulary handling\n\n:::{.callout-note}\n## Word2Vec Intuition\n- **Skip-gram**: Predicts context words given target word\n- **CBOW**: Predicts target word given context words\n- Both use hierarchical softmax or negative sampling for efficiency\n:::\n\n### Key Resources\n\n- [Word2Vec Paper](https://arxiv.org/abs/1301.3781) - Original Mikolov et al. work\n- [GloVe: Global Vectors](https://nlp.stanford.edu/projects/glove/) - Stanford implementation\n- [FastText](https://fasttext.cc/) - Facebook's subword embeddings\n\n### Learning Objectives\n\n1. Understand limitations of **one-hot encoding** and sparse representations\n2. Master the mathematics behind **Word2Vec training objectives**\n3. Implement **embedding evaluation** using intrinsic and extrinsic methods\n4. Analyze **semantic and syntactic** relationships in embedding spaces\n\n### Hands-on Session\n\n```python\n# Word2Vec training example\nfrom gensim.models import Word2Vec\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\n\n# Training and visualization pipeline\nmodel = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n# Visualize embeddings with t-SNE\n```\n\n**Practical Exercises**:\n- Training Word2Vec on domain-specific corpora\n- t-SNE visualization of embedding clusters\n- Word analogy tasks: \"king - man + woman = ?\"\n- Cross-lingual embedding alignment\n\n## Week 4: Neural Networks for NLP {#sec-week4}\n\n### Topic Overview\n\nThe neural revolution in NLP began with architectures designed for sequential data:\n\n- **Recurrent Neural Networks (RNNs)**: Processing variable-length sequences\n- **Long Short-Term Memory (LSTM)**: Solving the vanishing gradient problem\n- **Gated Recurrent Units (GRUs)**: Simplified gating mechanisms\n- **Bidirectional Networks**: Capturing both forward and backward context\n\n```{mermaid}\n%%| fig-cap: \"RNN Architecture Evolution\"\n%%| label: fig-rnn-evolution\ngraph LR\n    A[Vanilla RNN<br/>Vanishing Gradients] --> B[LSTM<br/>Forget Gate + Input Gate + Output Gate]\n    B --> C[GRU<br/>Reset Gate + Update Gate]\n    C --> D[BiLSTM<br/>Forward + Backward Processing]\n    \n    B --> E[Applications:<br/>Language Modeling<br/>Sequence Classification<br/>Named Entity Recognition]\n```\n\n### Learning Objectives\n\n- Design neural architectures for **sequence processing** tasks\n- Understand **gradient flow** in recurrent connections\n- Implement **bidirectional processing** for improved context modeling\n- Apply **regularization techniques** specific to sequential data\n\n### Hands-on Session\n\n**Implementation Focus**:\n- RNN-based language model implementation\n- LSTM vs. GRU comparison on sequence classification\n- Gradient clipping and other training stabilization techniques\n- Attention visualization in sequence-to-sequence models\n\n## Week 5: Attention Mechanisms and Transformers {#sec-week5}\n\n![Transformer Architecture](https://via.placeholder.com/600x450/FF9800/FFFFFF?text=Transformer+Architecture:+Self-Attention+%2B+Feed-Forward+%2B+Residual+Connections){#fig-transformer fig-alt=\"Detailed diagram of the Transformer architecture showing encoder-decoder structure\"}\n\n### Topic Overview\n\nThe attention mechanism fundamentally changed how we process sequences:\n\n- **Attention Intuition**: Differentiable dictionary lookup mechanism\n- **Self-Attention**: Query, Key, Value matrices and scaled dot-product\n- **Multi-Head Attention**: Parallel attention computations with different representations\n- **Transformer Architecture**: Complete replacement of recurrence with attention\n\n:::{.callout-important}\n## Attention Formula\nThe scaled dot-product attention is computed as:\n$$\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n\nWhere $Q$, $K$, $V$ are query, key, and value matrices respectively.\n:::\n\n### Key Resources\n\n- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Original Transformer paper\n- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) - Visual explanation\n- [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor) - Reference implementation\n\n### Learning Objectives\n\n1. Grasp the **mathematical intuition** behind attention mechanisms\n2. Understand **positional encoding** and why it's necessary\n3. Implement **multi-head attention** from scratch\n4. Analyze **computational complexity** advantages over RNNs\n\n### Hands-on Session\n\n```python\n# Self-attention implementation\nimport torch\nimport torch.nn as nn\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.d_model = d_model\n        self.num_heads = num_heads\n        # Implementation details...\n```\n\n**Practical Tasks**:\n- Implementing scaled dot-product attention\n- Building a mini-Transformer for sequence classification\n- Attention weight visualization and interpretation\n- Positional encoding analysis\n\n## Week 6: Large Language Models and Pre-training {#sec-week6}\n\n### Topic Overview\n\nThe era of large-scale pre-trained models has transformed NLP applications:\n\n- **Pre-training Paradigms**: From word prediction to masked language modeling\n- **BERT Family**: Bidirectional encoder representations from transformers\n- **GPT Series**: Autoregressive language model scaling\n- **Transfer Learning**: Fine-tuning strategies for downstream tasks\n\n```{mermaid}\n%%| fig-cap: \"Evolution of Large Language Models\"\n%%| label: fig-llm-timeline\ntimeline\n    title LLM Evolution Timeline\n    2018 : BERT (Google)\n         : GPT-1 (OpenAI)\n         : ELMo (AllenNLP)\n    2019 : GPT-2\n         : RoBERTa\n         : XLNet\n    2020 : GPT-3\n         : T5\n         : ELECTRA\n    2021 : PaLM\n         : Codex\n         : WebGPT\n    2022 : ChatGPT\n         : InstructGPT\n         : LaMDA\n    2023 : GPT-4\n         : Claude\n         : LLaMA\n```\n\n:::{.callout-note}\n## Pre-training Objectives\n- **Masked Language Modeling (MLM)**: Predict masked tokens (BERT)\n- **Causal Language Modeling (CLM)**: Predict next token (GPT)\n- **Prefix Language Modeling**: Hybrid approach (GLM, PaLM)\n:::\n\n### Learning Objectives\n\n- Understand different **pre-training strategies** and their trade-offs\n- Master **transfer learning** concepts for NLP applications\n- Analyze **scaling laws** and emergent capabilities in large models\n- Implement **fine-tuning pipelines** for specific tasks\n\n### Hands-on Session\n\n**Practical Applications**:\n- Fine-tuning BERT for text classification using [Hugging Face](https://huggingface.co/)\n- Prompt engineering with GPT models\n- Model comparison across different architectures\n- Efficient fine-tuning with parameter-efficient methods (LoRA, adapters)\n\n## Week 7: Evaluation and Ethics in NLP {#sec-week7}\n\n### Topic Overview\n\nResponsible AI development requires comprehensive evaluation and ethical considerations:\n\n- **Evaluation Methodologies**: Intrinsic vs. extrinsic evaluation frameworks\n- **Bias Detection**: Identifying and measuring algorithmic bias\n- **Fairness Metrics**: Demographic parity, equalized odds, individual fairness\n- **Environmental Impact**: Carbon footprint of large model training\n\n![Bias in NLP Systems](https://via.placeholder.com/550x350/F44336/FFFFFF?text=Bias+Sources:+Data+%2B+Algorithms+%2B+Applications+%3D+Societal+Impact){#fig-bias fig-alt=\"Diagram showing how bias enters NLP systems through data, algorithms, and applications\"}\n\n:::{.callout-warning}\n## Ethical Considerations\n- **Representation Bias**: Training data may not represent all populations\n- **Measurement Bias**: Evaluation metrics may favor certain groups\n- **Evaluation Bias**: Test sets may contain demographic skews\n- **Deployment Bias**: Real-world usage may differ from intended applications\n:::\n\n### Key Resources\n\n- [AI Fairness 360](https://aif360.readthedocs.io/) - IBM's bias detection toolkit\n- [What We Can't Measure, We Can't Understand](https://arxiv.org/abs/2109.09315) - Measurement in ML\n- [Blodgett et al., 2020](https://arxiv.org/abs/2005.14050) - Language models and bias\n\n### Learning Objectives\n\n1. Design **comprehensive evaluation frameworks** for NLP systems\n2. Identify and **quantify algorithmic bias** using statistical methods\n3. Implement **bias mitigation techniques** at different pipeline stages\n4. Consider **broader societal implications** of NLP deployment\n\n### Hands-on Session\n\n```python\n# Bias evaluation example\nfrom sklearn.metrics import confusion_matrix\nimport pandas as pd\n\n# Fairness metric calculation\ndef demographic_parity_difference(y_true, y_pred, sensitive_attr):\n    # Implementation for measuring bias across groups\n    pass\n```\n\n**Evaluation Tasks**:\n- Word embedding bias testing (WEAT, SEAT)\n- Fairness evaluation across demographic groups\n- Carbon footprint estimation for model training\n- Adversarial testing for robustness\n\n# Part II: Student Project Presentations {#sec-projects}\n\n## Project Categories and Detailed Descriptions\n\n### Category A: Text Classification and Analysis {#sec-classification}\n\n#### Project 1: Multi-label News Article Classification {#sec-project1}\n\n**Objective**: Build a robust multi-label classification system for news articles\n\n- **Dataset**: [Reuters-21578](http://www.daviddlewis.com/resources/testcollections/reuters21578/) or [BBC News Dataset](https://www.kaggle.com/c/learn-ai-bbc)\n- **Techniques**: Compare traditional ML (TF-IDF + SVM) vs. modern approaches (BERT, RoBERTa)\n- **Evaluation**: Multi-label F1, Hamming loss, subset accuracy\n- **Extensions**: Hierarchical classification, active learning for label efficiency\n\n:::{.callout-tip}\n## Technical Challenges\n- **Label Imbalance**: Some categories have very few examples\n- **Label Correlation**: Economic news often overlaps with political news\n- **Temporal Drift**: News topics evolve over time\n:::\n\n#### Project 2: Aspect-Based Sentiment Analysis {#sec-project2}\n\n**Objective**: Joint extraction of aspects and sentiment classification\n\n- **Dataset**: [SemEval ABSA datasets](http://alt.qcri.org/semeval2016/task5/), restaurant/hotel reviews\n- **Techniques**: Joint models for aspect extraction and sentiment classification\n- **Evaluation**: Aspect-level F1 scores, sentiment accuracy per aspect\n- **Extensions**: Cross-domain adaptation, multilingual ABSA\n\n```python\n# Example aspect-sentiment pairs\ntext = \"The pizza was delicious but the service was terrible.\"\naspects = [\n    (\"pizza\", \"positive\"),\n    (\"service\", \"negative\")\n]\n```\n\n#### Project 3: Fake News Detection with Explainability {#sec-project3}\n\n**Objective**: Build interpretable fake news detection systems\n\n- **Dataset**: [FakeNewsNet](https://github.com/KaiDMML/FakeNewsNet), [LIAR dataset](https://www.cs.ucsb.edu/~william/data/liar_dataset.zip)\n- **Techniques**: Feature engineering + deep learning + attention visualization\n- **Evaluation**: Classification metrics + human evaluation of explanations\n- **Extensions**: Multi-modal fake news detection (text + images)\n\n### Category B: Information Extraction and Retrieval {#sec-extraction}\n\n#### Project 4: Named Entity Recognition for Specialized Domains {#sec-project4}\n\n**Objective**: Develop domain-specific NER systems\n\n- **Dataset**: [BioBERT datasets](https://github.com/dmis-lab/biobert) (biomedical) or financial NER\n- **Techniques**: CRF vs. BERT-based sequence labeling\n- **Evaluation**: Entity-level F1, error analysis by entity type\n- **Extensions**: Few-shot NER, nested entity recognition\n\n#### Project 5: Open-Domain Question Answering System {#sec-project5}\n\n**Objective**: Build end-to-end question answering pipeline\n\n- **Dataset**: [Natural Questions](https://ai.google.com/research/NaturalQuestions/), [MS MARCO](https://microsoft.github.io/msmarco/)\n- **Architecture**: Dense Passage Retrieval + Reading Comprehension\n- **Evaluation**: Exact match, F1, answer coverage analysis\n- **Extensions**: Multi-hop reasoning, conversational QA\n\n```{mermaid}\n%%| fig-cap: \"Question Answering System Architecture\"\n%%| label: fig-qa-system\ngraph TB\n    A[Question] --> B[Query Encoder]\n    B --> C[Passage Retrieval]\n    C --> D[Passage Encoder]\n    D --> E[Answer Extraction]\n    E --> F[Answer]\n    \n    G[(Knowledge Base<br/>Wikipedia/Web)] --> C\n    H[Retriever Model<br/>DPR/ColBERT] --> C\n    I[Reader Model<br/>BERT/T5] --> E\n```\n\n#### Project 6: Automatic Fact Verification {#sec-project6}\n\n**Objective**: Verify claims against evidence sources\n\n- **Dataset**: [FEVER](https://fever.ai/dataset/fever.html) (Fact Extraction and VERification)\n- **Pipeline**: Evidence retrieval → Textual entailment → Verdict prediction\n- **Evaluation**: FEVER score, evidence selection accuracy\n- **Extensions**: Real-time fact-checking, claim generation\n\n### Category C: Text Generation and Summarization {#sec-generation}\n\n#### Project 7: Neural Abstractive Text Summarization {#sec-project7}\n\n**Objective**: Generate coherent abstractive summaries\n\n- **Dataset**: [CNN/DailyMail](https://github.com/abisee/cnn-dailymail), [XSum](https://github.com/EdinburghNLP/XSum)\n- **Techniques**: Encoder-decoder with attention, copy mechanisms, coverage\n- **Evaluation**: ROUGE scores, BERTScore, factual consistency\n- **Extensions**: Multi-document summarization, controllable length\n\n#### Project 8: Dialogue System with Personality {#sec-project8}\n\n**Objective**: Develop persona-consistent chatbots\n\n- **Dataset**: [PersonaChat](https://github.com/facebookresearch/ParlAI/tree/main/projects/personachat), [Blended Skill Talk](https://github.com/facebookresearch/ParlAI/tree/main/projects/blended_skill_talk)\n- **Techniques**: Persona-aware generation, retrieval-augmented responses\n- **Evaluation**: Automatic metrics + human evaluation for consistency\n- **Extensions**: Emotional intelligence, long-term memory\n\n#### Project 9: Creative Writing Assistant {#sec-project9}\n\n**Objective**: AI-powered creative content generation\n\n- **Dataset**: [WritingPrompts](https://www.reddit.com/r/WritingPrompts/), poetry corpora\n- **Techniques**: Fine-tuned GPT models with controlled generation\n- **Evaluation**: Creativity metrics, human preference studies, style analysis\n- **Extensions**: Interactive story writing, genre transfer\n\n### Category D: Multilingual and Low-Resource NLP {#sec-multilingual}\n\n#### Project 10: Cross-lingual Text Classification {#sec-project10}\n\n**Objective**: Zero-shot transfer across languages\n\n- **Dataset**: [MLDoc](https://github.com/facebookresearch/MLDoc), [XNLI](https://github.com/facebookresearch/XNLI)\n- **Techniques**: Multilingual BERT, cross-lingual word embeddings\n- **Evaluation**: Zero-shot transfer performance analysis\n- **Extensions**: Few-shot adaptation, code-switching handling\n\n#### Project 11: Machine Translation for Low-Resource Languages {#sec-project11}\n\n**Objective**: Improve translation for under-resourced languages\n\n- **Dataset**: [OPUS collections](http://opus.nlpl.eu/), WMT shared tasks\n- **Techniques**: Transfer learning, back-translation, multilingual models\n- **Evaluation**: BLEU, chrF, human evaluation, error analysis\n- **Extensions**: Pivot translation, unsupervised MT\n\n### Category E: Specialized Applications {#sec-specialized}\n\n#### Project 12: Legal Document Analysis {#sec-project12}\n\n**Objective**: Automated legal document processing\n\n- **Dataset**: Legal case documents, contracts, legislative texts\n- **Techniques**: Domain-adapted BERT, hierarchical document modeling\n- **Evaluation**: Legal expert evaluation, domain-specific metrics\n- **Extensions**: Legal precedent search, contract risk assessment\n\n#### Project 13: Medical Text Mining {#sec-project13}\n\n**Objective**: Clinical decision support through NLP\n\n- **Dataset**: [MIMIC-III](https://mimic.mit.edu/) clinical notes, PubMed abstracts\n- **Techniques**: BioBERT, clinical NER, relation extraction\n- **Evaluation**: Medical accuracy, clinical utility assessment\n- **Extensions**: Drug interaction prediction, diagnosis assistance\n\n#### Project 14: Mental Health Detection in Social Media {#sec-project14}\n\n**Objective**: Early detection of mental health indicators\n\n- **Dataset**: Reddit mental health datasets, Twitter emotion data\n- **Techniques**: Multi-modal analysis, temporal pattern modeling\n- **Evaluation**: Precision/recall for sensitive detection, ethical review\n- **Extensions**: Crisis intervention systems, privacy-preserving methods\n\n:::{.callout-warning}\n## Ethical Considerations for Mental Health Projects\n- **Privacy**: Anonymization and consent requirements\n- **Harm Prevention**: Avoiding false positives in crisis detection\n- **Professional Oversight**: Collaboration with mental health professionals\n- **Bias Mitigation**: Ensuring fair representation across demographics\n:::\n\n# Assessment Criteria {#sec-assessment}\n\n## Topic Presentations (Weeks 1-7) {#sec-topic-assessment}\n\n| Criterion | Weight | Description |\n|-----------|--------|-------------|\n| **Content Quality** | 40% | Research depth, technical accuracy, concept coverage |\n| **Presentation Skills** | 30% | Communication clarity, visual aids, audience engagement |\n| **Technical Implementation** | 30% | Code quality, demonstration effectiveness, innovation |\n\n: Assessment rubric for weekly topic presentations {#tbl-topic-rubric}\n\n## Project Presentations (Weeks 8-14) {#sec-project-assessment}\n\n| Criterion | Weight | Key Evaluation Points |\n|-----------|--------|---------------------|\n| **Technical Rigor** | 35% | Methodology selection, implementation quality, experimental design |\n| **Innovation** | 25% | Novel approaches, creative problem-solving, original insights |\n| **Results & Analysis** | 25% | Comprehensive evaluation, error analysis, baseline comparison |\n| **Communication** | 15% | Clear presentation, professional documentation, visualizations |\n\n: Assessment rubric for final project presentations {#tbl-project-rubric}\n\n:::{.callout-note}\n## Peer Evaluation Component\nStudents will also evaluate their peers' presentations using a structured rubric, contributing 10% to the final grade. This encourages active engagement and critical thinking.\n:::\n\n# Resources and Tools {#sec-resources}\n\n## Essential Python Libraries\n\n```python\n# Core NLP libraries\nimport nltk              # Natural Language Toolkit\nimport spacy             # Industrial-strength NLP\nimport transformers      # Hugging Face Transformers\nimport torch            # PyTorch for deep learning\nimport tensorflow as tf # TensorFlow alternative\n\n# Specialized libraries\nimport gensim           # Topic modeling and word embeddings\nimport scikit-learn     # Traditional ML algorithms\nimport datasets         # Hugging Face datasets\nimport evaluate         # Evaluation metrics\n```\n\n## Dataset Repositories\n\n- **[Hugging Face Datasets](https://huggingface.co/datasets)**: 10,000+ datasets for NLP\n- **[Papers with Code](https://paperswithcode.com/datasets)**: Benchmark datasets with leaderboards\n- **[Google Dataset Search](https://datasetsearch.research.google.com/)**: Comprehensive dataset discovery\n- **[Academic Torrents](https://academictorrents.com/)**: Large-scale research datasets\n\n## Evaluation Tools and Metrics\n\n- **Text Generation**: BLEU, ROUGE, BERTScore, METEOR\n- **Classification**: Precision, Recall, F1, AUC-ROC\n- **Sequence Labeling**: seqeval, entity-level F1\n- **Bias and Fairness**: Fairlearn, AI Fairness 360\n\n# Timeline and Milestones {#sec-timeline}\n\n```{mermaid}\n%%| fig-cap: \"Detailed Course Timeline with Milestones\"\n%%| label: fig-detailed-timeline\ngantt\n    title Detailed Course Timeline\n    dateFormat  YYYY-MM-DD\n    section Topic Presentations\n    Week 1: NLP Fundamentals      :active, t1, 2024-09-01, 7d\n    Week 2: Language Models       :t2, after t1, 7d\n    Week 3: Word Embeddings       :t3, after t2, 7d\n    Week 4: Neural Networks       :t4, after t3, 7d\n    Week 5: Transformers          :t5, after t4, 7d\n    Week 6: Large Language Models :t6, after t5, 7d\n    Week 7: Ethics & Evaluation   :t7, after t6, 7d\n    section Milestones\n    Project Proposal Due          :milestone, m1, 2024-10-01, 0d\n    Progress Check Meeting        :milestone, m2, 2024-11-01, 0d\n    Final Presentation           :milestone, m3, 2024-12-01, 0d\n    section Project Development\n    Project Phase 1              :p1, after t7, 21d\n    Project Phase 2              :p2, after p1, 21d\n    Final Presentations          :p3, after p2, 14d\n```\n\n## Key Milestones\n\n:::{.panel-tabset}\n\n### Week 4: Mid-Course Checkpoint\n- **Project proposal submission** (2-page document)\n- **Literature review** progress check\n- **Dataset acquisition** and preliminary analysis\n- **Technical approach** validation with instructor\n\n### Week 7: Proposal Presentations\n- **5-minute project pitches** to class\n- **Peer feedback** and suggestions\n- **Final project scope** confirmation\n- **Team formation** (if applicable)\n\n### Week 10: Progress Review\n- **Interim results** presentation\n- **Technical challenges** discussion\n- **Methodology adjustments** if needed\n- **Timeline reassessment** and planning\n\n### Week 13-14: Final Presentations\n- **15-minute presentations** with Q&A\n- **Live demonstrations** of working systems\n- **Peer evaluation** and feedback\n- **Industry guest evaluators** (when possible)\n\n:::\n\n# Additional Course Information {#sec-additional}\n\n## Collaboration and Academic Integrity\n\n- **Individual Work**: Weekly topic presentations must be completed individually\n- **Team Projects**: Final projects may be completed in teams of maximum 2 students\n- **Code Sharing**: All implementations must be original with proper attribution\n- **Plagiarism Policy**: Zero tolerance for academic dishonesty\n\n## Technical Requirements\n\n:::{.callout-important}\n## Submission Requirements\n- **Version Control**: All projects must use Git with clear commit history\n- **Reproducibility**: Include requirements.txt and detailed setup instructions\n- **Documentation**: README with project description, usage, and results\n- **Public Repository**: GitHub repository with appropriate license\n:::\n\n## Support and Office Hours\n\n- **Weekly Office Hours**: Tuesdays 2-4 PM and Thursdays 10-12 PM\n- **Online Forum**: Course Slack workspace for peer discussion\n- **Technical Support**: TA sessions for implementation help\n- **Guest Speakers**: Industry professionals and researchers (select weeks)\n\n## Computing Resources\n\nStudents have access to:\n- **Local GPUs**: NVIDIA RTX 4090 for model training\n- **Cloud Credits**: $100 Google Cloud Platform credits per student\n- **Cluster Access**: University HPC cluster for large-scale experiments\n- **Pretrained Models**: Access to Hugging Face Pro for latest models\n\n---\n\n*This course syllabus is subject to updates based on student needs and emerging trends in NLP research. All changes will be communicated through the course management system.*\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"output-file":"overview.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.33","theme":["cosmo","brand"],"title":"Introduction to Natural Language Processing Course","author":"A.Belcaid","date":"09-01-2025","bibliography":["references.bib"],"fig-cap-location":"bottom"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}